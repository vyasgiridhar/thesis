@inproceedings{1,
  author    = {Yeh, Chin-Chia Michael and Zhu, Yan and Ulanova, Liudmila and Begum, Nurjahan and Ding, Yifei and Dau, Hoang Anh and Silva, Diego Furtado and Mueen, Abdullah and Keogh, Eamonn},
  booktitle = {2016 IEEE 16th International Conference on Data Mining (ICDM)},
  title     = {Matrix Profile I: All Pairs Similarity Joins for Time Series: A Unifying View That Includes Motifs, Discords and Shapelets},
  year      = {2016},
  volume    = {},
  number    = {},
  pages     = {1317-1322},
  keywords  = {Time series analysis;Approximation algorithms;Euclidean distance;Data mining;Indexes;Clustering algorithms;Text processing;Time Series;Similarity Joins;Motif Discovery},
  doi       = {10.1109/ICDM.2016.0179}
}

@inproceedings{2,
  author    = {Zhu, Yan and Zimmerman, Zachary and Senobari, Nader Shakibay and Yeh, Chin-Chia Michael and Funning, Gareth and Mueen, Abdullah and Brisk, Philip and Keogh, Eamonn},
  booktitle = {2016 IEEE 16th International Conference on Data Mining (ICDM)},
  title     = {Matrix Profile II: Exploiting a Novel Algorithm and GPUs to Break the One Hundred Million Barrier for Time Series Motifs and Joins},
  year      = {2016},
  volume    = {},
  number    = {},
  pages     = {739-748},
  keywords  = {Time series analysis;Earthquakes;Seismology;Scalability;Data mining;Graphics processing units;Indexes;Time series;joins;motifs;GPUs},
  doi       = {10.1109/ICDM.2016.0085}
}

@inproceedings{8594908,
  author    = {Zhu, Yan and Yeh, Chin-Chia Michael and Zimmerman, Zachary and Kamgar, Kaveh and Keogh, Eamonn},
  booktitle = {2018 IEEE International Conference on Data Mining (ICDM)},
  title     = {Matrix Profile XI: SCRIMP++: Time Series Motif Discovery at Interactive Speeds},
  year      = {2018},
  volume    = {},
  number    = {},
  pages     = {837-846},
  keywords  = {Time series analysis;Approximation algorithms;Data mining;Neuroscience;Task analysis;Games;Batch production systems;Time Series;Anytime Algorithms;Motif Discovery},
  doi       = {10.1109/ICDM.2018.00099}
}


@misc{3,
  title         = {Cerebras-GPT: Open Compute-Optimal Language Models Trained on the Cerebras Wafer-Scale Cluster},
  author        = {Nolan Dey and Gurpreet Gosal and Zhiming and Chen and Hemant Khachane and William Marshall and Ribhu Pathria and Marvin Tom and Joel Hestness},
  year          = {2023},
  eprint        = {2304.03208},
  archiveprefix = {arXiv},
  primaryclass  = {cs.LG}
}
@inproceedings{8215484,
  author    = {Gharghabi, Shaghayegh and Ding, Yifei and Yeh, Chin-Chia Michael and Kamgar, Kaveh and Ulanova, Liudmila and Keogh, Eamonn},
  booktitle = {2017 IEEE International Conference on Data Mining (ICDM)},
  title     = {Matrix Profile VIII: Domain Agnostic Online Semantic Segmentation at Superhuman Performance Levels},
  year      = {2017},
  volume    = {},
  number    = {},
  pages     = {117-126},
  keywords  = {Time series analysis;Semantics;Hidden Markov models;Heart;Clustering algorithms;Motion segmentation;Sensors;Time Series;Semantic Segmentation;Online Algorithms},
  doi       = {10.1109/ICDM.2017.21}
}

@inproceedings{4,
  author    = {Zimmerman, Zachary and Kamgar, Kaveh and Senobari, Nader Shakibay and Crites, Brian and Funning, Gareth and Brisk, Philip and Keogh, Eamonn},
  title     = {Matrix Profile XIV: Scaling Time Series Motif Discovery with GPUs to Break a Quintillion Pairwise Comparisons a Day and Beyond},
  year      = {2019},
  isbn      = {9781450369732},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  url       = {https://doi.org/10.1145/3357223.3362721},
  doi       = {10.1145/3357223.3362721},
  booktitle = {Proceedings of the ACM Symposium on Cloud Computing},
  pages     = {74–86},
  numpages  = {13},
  keywords  = {AB-Join, Cloud Computing, Entomology, Fault-Tolerance, GPU, Matrix Profile, Numerical Optimization, SCAMP, Seismology, Self-Join, Spot Instance, Tiling, Time Series},
  location  = {Santa Cruz, CA, USA},
  series    = {SoCC '19}
}

@article{10460211,
  author   = {Hu, Yang and Lin, Xinhan and Wang, Huizheng and He, Zhen and Yu, Xingmao and Zhang, Jiahao and Yang, Qize and Xu, Zheng and Guan, Sihan and Fang, Jiahao and Shang, Haoran and Tang, Xinru and Dai, Xu and Wei, Shaojun and Yin, Shouyi},
  journal  = {IEEE Circuits and Systems Magazine},
  title    = {Wafer-Scale Computing: Advancements, Challenges, and Future Perspectives [Feature]},
  year     = {2024},
  volume   = {24},
  number   = {1},
  pages    = {52-81},
  keywords = {Wafer scale integration;Artificial intelligence;Hardware design languages;Transistors;Bandwidth;Chip scale packaging;Integrated circuit interconnections;Costs;Fault tolerant systems;Software systems;Computer architecture;AI chip;waferscale-computing;hardware architecture;software system},
  doi      = {10.1109/MCAS.2024.3349669}
}

@article{257870,
  author   = {Campbell, M.L. and Toborg, S.T.},
  journal  = {IEEE Transactions on Components, Hybrids, and Manufacturing Technology},
  title    = {3-D wafer scale architectures for neural network computing},
  year     = {1993},
  volume   = {16},
  number   = {7},
  pages    = {646-655},
  keywords = {Computer architecture;Neural networks;Computer networks;Prototypes;Neural network hardware;Backpropagation algorithms;Multi-layer neural network;Semiconductor device modeling;CMOS technology;Wafer scale integration},
  doi      = {10.1109/33.257870}
}

@misc{vanputten2024slide,
  title         = {Slide FFT on a homogeneous mesh in wafer-scale computing},
  author        = {Maurice H. P. M. van Putten and Leighton Wilson and Adam W. Lavely and Mark Hair},
  year          = {2024},
  eprint        = {2401.05427},
  archiveprefix = {arXiv},
  primaryclass  = {eess.SP}
}
@inproceedings{5,
  author    = {Jacquelin, Mathias and Araya-Polo, Mauricio and Meng, Jie},
  title     = {Scalable distributed high-order stencil computations},
  year      = {2022},
  isbn      = {9784665454445},
  publisher = {IEEE Press},
  abstract  = {Stencil computations lie at the heart of many scientific and industrial applications. Stencil algorithms pose several challenges on machines with cache based memory hierarchy, due to low re-use of memory accesses if special care is not taken to optimize them. This work shows that for stencil computation a novel algorithm that leverages a localized communication strategy effectively exploits the second generation Cerebras Wafer-Scale Engine (WSE-2), which has no cache hierarchy. This study focuses on a 25-point stencil finite-difference method for the 3D wave equation, a kernel frequently used in earth modeling as numerical simulation. In essence, the algorithm trades memory accesses for data communication and takes advantage of the fast communication fabric provided by the architecture. The algorithm ---historically memory-bound--- becomes compute-bound. This allows the implementation to achieve near perfect weak scaling, reaching up to 503 TFLOPs on WSE-2, a figure that only full clusters can eventually yield.},
  booktitle = {Proceedings of the International Conference on High Performance Computing, Networking, Storage and Analysis},
  articleno = {30},
  numpages  = {13},
  keywords  = {wafer-scale, stencil computation, multi-processor architecture and micro-architecture, high performance computing, energy, distributed memory},
  location  = {Dallas, Texas},
  series    = {SC '22}
}

@inproceedings{6,
  author    = {Orenes-Vera, Marcelo and Sharapov, Ilya and Schreiber, Robert and Jacquelin, Mathias and Vandermersch, Philippe and Chetlur, Sharan},
  title     = {Wafer-Scale Fast Fourier Transforms},
  year      = {2023},
  isbn      = {9798400700569},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  url       = {https://doi.org/10.1145/3577193.3593708},
  doi       = {10.1145/3577193.3593708},
  abstract  = {We have implemented fast Fourier transforms for one, two, and three-dimensional arrays on the Cerebras CS-2, a system whose memory and processing elements reside on a single silicon wafer. The wafer-scale engine (WSE) encompasses a two-dimensional mesh of roughly 850,000 processing elements (PEs) with fast local memory and equally fast nearest-neighbor interconnections.Our wafer-scale FFT (wsFFT) parallelizes a n3 problem with up to n2 PEs. At this point, a PE processes only a single vector of the 3D domain (known as a pencil) per superstep, where each of the three supersteps performs FFT along one of the three axes of the input array. Between supersteps, wsFFT redistributes (transposes) the data to bring all elements of each one-dimensional pencil being transformed into the memory of a single PE. Each redistribution causes an all-to-all communication along one of the mesh dimensions. Given the level of parallelism, the size of the messages transmitted between pairs of PEs can be as small as a single word. In theory, a mesh is not ideal for all-to-all communication due to its limited bisection bandwidth. However, the mesh interconnecting PEs on the WSE lies entirely on-wafer and achieves nearly peak bandwidth even with tiny messages.We analyze in detail computation and communication time, as well as the weak and strong scaling, using both FP16 and FP32 precision. With 32-bit arithmetic on the CS-2, we achieve 959 microseconds for 3D FFT of a 5123 complex input array using a 512 \texttimes{} 512 subgrid of the on-wafer PEs. This is the largest ever parallelization for this problem size and the first implementation that breaks the millisecond barrier.},
  booktitle = {Proceedings of the 37th International Conference on Supercomputing},
  pages     = {180–191},
  numpages  = {12},
  keywords  = {FFT, wafer-scale, strong scaling, massive parallelization, explicit communication, mesh, network, bandwidth, programming models},
  location  = {Orlando, FL, USA},
  series    = {ICS '23}
}

@article{7,
  title    = {Efficient algorithms for Monte Carlo particle transport on AI accelerator hardware},
  journal  = {Computer Physics Communications},
  volume   = {298},
  pages    = {109072},
  year     = {2024},
  issn     = {0010-4655},
  doi      = {https://doi.org/10.1016/j.cpc.2023.109072},
  url      = {https://www.sciencedirect.com/science/article/pii/S0010465523004174},
  author   = {John Tramm and Bryce Allen and Kazutomo Yoshii and Andrew Siegel and Leighton Wilson},
  keywords = {High performance computing, Monte Carlo particle transport, Macroscopic cross section lookup, AI accelerators, Cerebras},
  abstract = {The recent trend toward deep learning has led to the development of a variety of highly innovative AI accelerator architectures. One such architecture, the Cerebras Wafer-Scale Engine 2 (WSE-2), features 40 GB of on-chip SRAM, making it a potentially attractive platform for latency- or bandwidth-bound HPC simulation workloads. In this study, we examine the feasibility of performing continuous energy Monte Carlo (MC) particle transport on the WSE-2 by porting a key kernel from the MC transport algorithm to Cerebras's CSL programming model. New algorithms for minimizing communication costs and for handling load balancing are developed and tested. The WSE-2 is found to run 130 times faster than a highly optimized CUDA version of the kernel run on an NVIDIA A100 GPU—significantly outpacing the expected performance increase given the difference in transistor counts between the architectures.}
}

@misc{8,
  title  = {The UCR Time Series Classification Archive},
  author = {Dau, Hoang Anh and Keogh, Eamonn and Kamgar, Kaveh and Yeh, Chin-Chia Michael and Zhu, Yan 
            and Gharghabi, Shaghayegh and Ratanamahatana, Chotirat Ann and Yanping and Hu, Bing 
            and Begum, Nurjahan and Bagnall, Anthony and Mueen, Abdullah and Batista, Gustavo, and Hexagon-ML},
  year   = {2018},
  month  = {8},
  note   = {\url{https://www.cs.ucr.edu/~eamonn/time_series_data_2018/}}
}

@misc{9,
  title         = {Massively scalable stencil algorithm},
  author        = {Mathias Jacquelin and Mauricio Araya-Polo and Jie Meng},
  year          = {2022},
  eprint        = {2204.03775},
  archiveprefix = {arXiv},
  primaryclass  = {cs.MS}
}

@article{10,
  author  = {Grosser, Tobias and Verdoolaege, Sven and Cohen, Albert and Sadayappan, Ponnuswamy},
  year    = {2014},
  month   = {09},
  pages   = {},
  title   = {The Relation Between Diamond Tiling and Hexagonal Tiling},
  volume  = {24},
  journal = {Parallel Processing Letters},
  doi     = {10.1142/S0129626414410023}
}

@inproceedings{11,
  author = {Wonnacott, David and Strout, Michelle},
  year   = {2013},
  month  = {01},
  pages  = {},
  title  = {On the Scalability of Loop Tiling Techniques}
}

@misc{12,
  author       = {Sean Lie},
  title        = {cerebras.net},
  howpublished = {\url{https://www.cerebras.net/wp-content/uploads/2022/08/efficient-local-memory.jpg}},
  year         = {2022},
  note         = {[Accessed 03-03-2024]}
}

@misc{UCRArchive2018,
  title  = {The UCR Time Series Classification Archive},
  author = {Dau, Hoang Anh and Keogh, Eamonn and Kamgar, Kaveh and Yeh, Chin-Chia Michael and Zhu, Yan 
            and Gharghabi, Shaghayegh and Ratanamahatana, Chotirat Ann and Yanping and Hu, Bing 
            and Begum, Nurjahan and Bagnall, Anthony and Mueen, Abdullah and Batista, Gustavo, and Hexagon-ML},
  year   = {2018},
  month  = {October},
  note   = {\url{https://www.cs.ucr.edu/~eamonn/time_series_data_2018/}}
}

@article{10.1093/gji/ggy100,
  author   = {Bergen, Karianne J and Beroza, Gregory C},
  title    = {{Detecting earthquakes over a seismic network using single-station similarity measures}},
  journal  = {Geophysical Journal International},
  volume   = {213},
  number   = {3},
  pages    = {1984-1998},
  year     = {2018},
  month    = {03},
  abstract = {{New blind waveform-similarity-based detection methods, such as Fingerprint and Similarity Thresholding (FAST), have shown promise for detecting weak signals in long-duration, continuous waveform data. While blind detectors are capable of identifying similar or repeating waveforms without templates, they can also be susceptible to false detections due to local correlated noise. In this work, we present a set of three new methods that allow us to extend single-station similarity-based detection over a seismic network; event-pair extraction, pairwise pseudo-association, and event resolution complete a post-processing pipeline that combines single-station similarity measures (e.g. FAST sparse similarity matrix) from each station in a network into a list of candidate events. The core technique, pairwise pseudo-association, leverages the pairwise structure of event detections in its network detection model, which allows it to identify events observed at multiple stations in the network without modeling the expected moveout. Though our approach is general, we apply it to extend FAST over a sparse seismic network. We demonstrate that our network-based extension of FAST is both sensitive and maintains a low false detection rate. As a test case, we apply our approach to 2 weeks of continuous waveform data from five stations during the foreshock sequence prior to the 2014 Mw 8.2 Iquique earthquake. Our method identifies nearly five times as many events as the local seismicity catalogue (including 95 per cent of the catalogue events), and less than 1 per cent of these candidate events are false detections.}},
  issn     = {0956-540X},
  doi      = {10.1093/gji/ggy100},
  url      = {https://doi.org/10.1093/gji/ggy100},
  eprint   = {https://academic.oup.com/gji/article-pdf/213/3/1984/24638013/ggy100.pdf}
}


@inproceedings{Fox_2017,
  series     = {KDD ’17},
  title      = {Contextual Motifs: Increasing the Utility of Motifs using Contextual Data},
  url        = {http://dx.doi.org/10.1145/3097983.3098068},
  doi        = {10.1145/3097983.3098068},
  booktitle  = {Proceedings of the 23rd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
  publisher  = {ACM},
  author     = {Fox, Ian and Ang, Lynn and Jaiswal, Mamta and Pop-Busui, Rodica and Wiens, Jenna},
  year       = {2017},
  month      = aug,
  collection = {KDD ’17}
}

@inproceedings{Silva2016SiMPleAM,
  title     = {SiMPle: Assessing Music Similarity Using Subsequences Joins},
  author    = {Diego Furtado Silva and Chin-Chia Michael Yeh and Gustavo E. A. P. A. Batista and Eamonn J. Keogh},
  booktitle = {International Society for Music Information Retrieval Conference},
  year      = {2016},
  url       = {https://api.semanticscholar.org/CorpusID:14118722}
}